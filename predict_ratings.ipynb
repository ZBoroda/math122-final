{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Product Ratings From Web Browsing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matrix_completion import MatrixCompletionizationizer\n",
    "from utils import *\n",
    "\n",
    "# load the browsing history data\n",
    "user_history = pd.read_csv(\"user_history.csv\")\n",
    "user_history_without_user_ID = user_history.drop(['USER ID'],axis=1)\n",
    "user_history_indexed = user_history.set_index('USER ID')\n",
    "user_ratings = pd.read_csv(\"user_ratings.csv\")\n",
    "user_history_indexed_normalized = user_history_indexed.copy()\n",
    "user_history_indexed_normalized -= user_history_indexed_normalized.mean()\n",
    "user_history_indexed_normalized /= user_history_indexed_normalized.std()\n",
    "\n",
    "# load the ratings data\n",
    "train, test = split_data('user_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_SELECTION_METHODS = [\"All features\", \"PCA\", \"KMeans then PCA\", \"all\"]\n",
    "MATRIX_COMPLETION_METHODS = [\"Use web features as initial user features\", \"Append web features\"]\n",
    "\n",
    "FEATURE_SELECTION = FEATURE_SELECTION_METHODS[2] #set this to 0, 1, or 2, or 3 for \"all\"\n",
    "MATRIX_COMPLETION = MATRIX_COMPLETION_METHODS[1] #set this to 0 or 1\n",
    "\n",
    "#set hyperparameters here:\n",
    "learning_rate = 0.005\n",
    "num_epochs = 2000\n",
    "batch_size = 3000\n",
    "k = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Using unmodified web browsing data as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FEATURE_SELECTION == \"All features\" or FEATURE_SELECTION == \"all\":\n",
    "    row_id_to_ind = dict(zip(user_history['USER ID'].to_numpy(), range(len(user_history['USER ID'].to_numpy()))))\n",
    "    n_rows = len(row_id_to_ind)\n",
    "    col_id_to_ind = dict(zip(train['PRODUCT'].unique(), range(len(train['PRODUCT'].unique()))))\n",
    "    n_cols = len(col_id_to_ind)\n",
    "    \n",
    "    reduced_features = user_history_indexed_normalized\n",
    "\n",
    "    added_cols = reduced_features\n",
    "    added_col_id_to_ind = dict(zip(added_cols.columns.to_numpy(), range(n_cols, n_cols+added_cols.shape[1])))\n",
    "    all_cols_id_to_ind = {**col_id_to_ind, **added_col_id_to_ind}\n",
    "    added_cols_melted = added_cols.reset_index(inplace=False).melt('USER ID', var_name='PRODUCT', value_name='RATING')\n",
    "    n_all_cols = len(all_cols_id_to_ind)\n",
    "\n",
    "    train_appended = pd.concat([train, added_cols_melted], axis=0) \n",
    "    train_appended = train_appended.reset_index().drop(columns=['index'])\n",
    "\n",
    "    train_ratings = train['RATING']\n",
    "    train_rows = train['USER ID']\n",
    "    train_cols = train['PRODUCT']\n",
    "\n",
    "    train_ratings_appended = train_appended['RATING']\n",
    "    train_rows_appended = train_appended['USER ID']\n",
    "    train_cols_appended = train_appended['PRODUCT']\n",
    "\n",
    "    test_ratings = test['RATING']\n",
    "    test_rows = test['USER ID']\n",
    "    test_cols = test['PRODUCT']\n",
    "\n",
    "    row_features = reduced_features.to_numpy()\n",
    "    \n",
    "    if MATRIX_COMPLETION == \"Append web features\":\n",
    "        model = MatrixCompletionizationizer(n_rows, n_all_cols, k=k)\n",
    "        predicted = model.train(train_rows_appended, train_cols_appended, train_ratings_appended,\n",
    "                                row_id_to_ind, all_cols_id_to_ind,\n",
    "                                num_epochs=num_epochs, batch_size=batch_size, learning_rate = learning_rate,\n",
    "                                print_loss = True, graph_loss = True, \n",
    "                                original_train_rows=train_rows, original_train_cols=train_cols, \n",
    "                                original_train_vals=train_ratings, original_col_id_to_ind=col_id_to_ind)\n",
    "    elif MATRIX_COMPLETION == \"Use web features as initial user features\":\n",
    "        model = MatrixCompletionizationizer(n_rows, n_cols, row_features=row_features)        \n",
    "        predicted = model.train(train_rows, train_cols, train_ratings,\n",
    "                                row_id_to_ind, col_id_to_ind,\n",
    "                                num_epochs=num_epochs, batch_size=batch_size, learning_rate = learning_rate,\n",
    "                                print_loss = True, graph_loss = True)\n",
    "\n",
    "    test_rows_inds = np.array([row_id_to_ind[r] for r in test_rows])\n",
    "    test_cols_inds = np.array([col_id_to_ind[c] for c in test_cols])\n",
    "\n",
    "    print()\n",
    "    print(\"Test MSE for using unprocessed history matrix:\")\n",
    "    print(mse(test_ratings, predicted[test_rows_inds, test_cols_inds]))\n",
    "    print()\n",
    "    print(\"Average test error (square root of MSE) for using unprocessed history matrix:\")\n",
    "    print(np.sqrt(mse(test_ratings, predicted[test_rows_inds, test_cols_inds])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Using web browsing data after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FEATURE_SELECTION == \"PCA\" or FEATURE_SELECTION == \"all\":\n",
    "    row_id_to_ind = dict(zip(user_history['USER ID'].to_numpy(), range(len(user_history['USER ID'].to_numpy()))))\n",
    "    n_rows = len(row_id_to_ind)\n",
    "    col_id_to_ind = dict(zip(train['PRODUCT'].unique(), range(len(train['PRODUCT'].unique()))))\n",
    "    n_cols = len(col_id_to_ind)\n",
    "\n",
    "    reduced_features = PCA(user_history_indexed_normalized, user_history['USER ID'],\n",
    "                           spectrum_fraction_threshold=0.9, graph_spectrum_fractions=False)\n",
    "\n",
    "    added_cols = reduced_features\n",
    "    added_col_id_to_ind = dict(zip(added_cols.columns.to_numpy(), range(n_cols, n_cols+added_cols.shape[1])))\n",
    "    all_cols_id_to_ind = {**col_id_to_ind, **added_col_id_to_ind}\n",
    "    added_cols_melted = added_cols.reset_index(inplace=False).melt('USER ID', var_name='PRODUCT', value_name='RATING')\n",
    "    n_all_cols = len(all_cols_id_to_ind)\n",
    "\n",
    "    train_appended = pd.concat([train, added_cols_melted], axis=0) \n",
    "    train_appended = train_appended.reset_index().drop(columns=['index'])\n",
    "\n",
    "    train_ratings = train['RATING']\n",
    "    train_rows = train['USER ID']\n",
    "    train_cols = train['PRODUCT']\n",
    "\n",
    "    train_ratings_appended = train_appended['RATING']\n",
    "    train_rows_appended = train_appended['USER ID']\n",
    "    train_cols_appended = train_appended['PRODUCT']\n",
    "\n",
    "    test_ratings = test['RATING']\n",
    "    test_rows = test['USER ID']\n",
    "    test_cols = test['PRODUCT']\n",
    "\n",
    "    row_features = reduced_features.to_numpy()\n",
    "    \n",
    "    if MATRIX_COMPLETION == \"Append web features\":\n",
    "        model = MatrixCompletionizationizer(n_rows, n_all_cols, k=k)\n",
    "        predicted = model.train(train_rows_appended, train_cols_appended, train_ratings_appended,\n",
    "                                row_id_to_ind, all_cols_id_to_ind,\n",
    "                                num_epochs=num_epochs, batch_size=batch_size, learning_rate = learning_rate,\n",
    "                                print_loss = True, graph_loss = True, \n",
    "                                original_train_rows=train_rows, original_train_cols=train_cols, \n",
    "                                original_train_vals=train_ratings, original_col_id_to_ind=col_id_to_ind)\n",
    "    elif MATRIX_COMPLETION == \"Use web features as initial user features\":\n",
    "        model = MatrixCompletionizationizer(n_rows, n_cols, row_features=row_features)        \n",
    "        predicted = model.train(train_rows, train_cols, train_ratings,\n",
    "                                row_id_to_ind, col_id_to_ind,\n",
    "                                num_epochs=num_epochs, batch_size=batch_size, learning_rate = learning_rate,\n",
    "                                print_loss = True, graph_loss = True)\n",
    "\n",
    "    test_rows_inds = np.array([row_id_to_ind[r] for r in test_rows])\n",
    "    test_cols_inds = np.array([col_id_to_ind[c] for c in test_cols])\n",
    "\n",
    "    print()\n",
    "    print(\"Test MSE for PCA on entire history matrix:\")\n",
    "    print(mse(test_ratings, predicted[test_rows_inds, test_cols_inds]))\n",
    "    print()\n",
    "    print(\"Average test error (square root of MSE) for PCA on entire history matrix:\")\n",
    "    print(np.sqrt(mse(test_ratings, predicted[test_rows_inds, test_cols_inds])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Using web browsing data after PCA on individual clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch #1 is: 22.326847226082684\n",
      "Train loss after epoch #200 is: 3.9231473576596305\n",
      "Train loss after epoch #400 is: 0.8488907036923186\n",
      "Train loss after epoch #600 is: 0.4079206399977904\n",
      "Train loss after epoch #800 is: 0.2819348356540602\n",
      "Train loss after epoch #1000 is: 0.22928117332218695\n",
      "Train loss after epoch #1200 is: 0.19508237106721776\n",
      "Train loss after epoch #1400 is: 0.17206247992473406\n"
     ]
    }
   ],
   "source": [
    "if FEATURE_SELECTION == \"KMeans then PCA\" or FEATURE_SELECTION == \"all\":\n",
    "    num_clusters = 3\n",
    "    reduced_cluster_data, user_history_clustered = KMeansPCA(user_history_indexed_normalized, user_history['USER ID'], 'USER ID', \n",
    "                                                             num_clusters=num_clusters, spectrum_fraction_threshold=0.9,\n",
    "                                                             plot_clusters=False)\n",
    "    train_with_clusters = train.merge(pd.DataFrame(user_history_clustered['Cluster']).reset_index())\n",
    "    test_with_clusters = test.merge(pd.DataFrame(user_history_clustered['Cluster']).reset_index())\n",
    "\n",
    "    for cluster_ind in range(num_clusters):\n",
    "\n",
    "        train = train_with_clusters[train_with_clusters['Cluster']==cluster_ind].drop(columns=['Cluster'])\n",
    "        test = test_with_clusters[test_with_clusters['Cluster']==cluster_ind].drop(columns=['Cluster'])\n",
    "\n",
    "        cluster_inds = reduced_cluster_data[cluster_ind].reset_index()['USER ID'].unique()\n",
    "        row_id_to_ind_cluster = dict(zip(cluster_inds, range(len(cluster_inds))))\n",
    "        col_id_to_ind = dict(zip(train['PRODUCT'].unique(), range(len(train['PRODUCT'].unique()))))\n",
    "        n_rows = len(row_id_to_ind_cluster)\n",
    "        n_cols = len(col_id_to_ind)\n",
    "\n",
    "        reduced_features = reduced_cluster_data[cluster_ind].sort_index()\n",
    "        added_cols = reduced_features\n",
    "        added_col_id_to_ind = dict(zip(added_cols.columns.to_numpy(), range(n_cols, n_cols+added_cols.shape[1])))\n",
    "        all_cols_id_to_ind = {**col_id_to_ind, **added_col_id_to_ind}\n",
    "        added_cols_melted = added_cols.reset_index(inplace=False).melt('USER ID', var_name='PRODUCT', value_name='RATING')\n",
    "        n_all_cols = len(all_cols_id_to_ind)\n",
    "\n",
    "        train_appended = pd.concat([train, added_cols_melted], axis=0) \n",
    "        train_appended = train_appended.reset_index().drop(columns=['index'])\n",
    "\n",
    "        train_ratings = train['RATING']\n",
    "        train_rows = train['USER ID']\n",
    "        train_cols = train['PRODUCT']\n",
    "\n",
    "        train_ratings_appended = train_appended['RATING']\n",
    "        train_rows_appended = train_appended['USER ID']\n",
    "        train_cols_appended = train_appended['PRODUCT']\n",
    "\n",
    "        test_ratings = test['RATING']\n",
    "        test_rows = test['USER ID']\n",
    "        test_cols = test['PRODUCT']\n",
    "\n",
    "        row_features = reduced_features.to_numpy()\n",
    "    \n",
    "        if MATRIX_COMPLETION == \"Append web features\":\n",
    "            model = MatrixCompletionizationizer(n_rows, n_all_cols, k=k)\n",
    "            predicted = model.train(train_rows_appended, train_cols_appended, train_ratings_appended,\n",
    "                                    row_id_to_ind_cluster, all_cols_id_to_ind,\n",
    "                                    num_epochs=num_epochs, batch_size=batch_size, learning_rate = learning_rate,\n",
    "                                    print_loss = True, graph_loss = True, \n",
    "                                    original_train_rows=train_rows, original_train_cols=train_cols, \n",
    "                                    original_train_vals=train_ratings, original_col_id_to_ind=col_id_to_ind)\n",
    "        elif MATRIX_COMPLETION == \"Use web features as initial user features\":\n",
    "            model = MatrixCompletionizationizer(n_rows, n_cols, row_features=row_features)        \n",
    "            predicted = model.train(train_rows, train_cols, train_ratings,\n",
    "                                    row_id_to_ind_cluster, col_id_to_ind,\n",
    "                                    num_epochs=num_epochs, batch_size=batch_size, learning_rate = learning_rate,\n",
    "                                    print_loss = True, graph_loss = True)\n",
    "\n",
    "        test_rows_inds = np.array([row_id_to_ind_cluster[r] for r in test_rows])\n",
    "        test_cols_inds = np.array([all_cols_id_to_ind[c] for c in test_cols])\n",
    "        print()\n",
    "        print(\"Test MSE for cluster #\" + str(cluster_ind) + \":\")\n",
    "        print(mse(test_ratings, predicted[test_rows_inds, test_cols_inds]))\n",
    "        print()\n",
    "        print(\"Average test error (square root of MSE) for cluster #\" + str(cluster_ind) + \":\")\n",
    "        print(np.sqrt(mse(test_ratings, predicted[test_rows_inds, test_cols_inds])))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
