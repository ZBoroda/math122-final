{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful packages\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# load the browsing history data\n",
    "user_history = pd.read_csv(\"user_history.csv\")\n",
    "user_history_without_user_ID = user_history.drop(['USER ID'],axis=1)\n",
    "user_history_indexed = user_history.set_index('USER ID')\n",
    "user_ratings = pd.read_csv(\"user_ratings.csv\")\n",
    "\n",
    "# load the ratings data\n",
    "train = pd.read_csv(\"train_rating.csv\")\n",
    "test = pd.read_csv(\"test_rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_id_to_ind = dict(zip(user_history['USER ID'].to_numpy(), range(len(user_history['USER ID'].to_numpy()))))\n",
    "ind_to_row_id = dict(zip(range(len(user_history['USER ID'].to_numpy())), user_history['USER ID'].to_numpy()))\n",
    "\n",
    "website_id_to_ind = dict(zip(user_history_indexed.columns.to_numpy(), range(len(user_history_indexed.columns.to_numpy()))))\n",
    "ind_to_website_id = dict(zip(range(len(user_history_indexed.columns.to_numpy())), user_history_indexed.columns.to_numpy()))\n",
    "\n",
    "col_id_to_ind = dict(zip(train['PRODUCT'].unique(), range(len(train['PRODUCT'].unique()))))\n",
    "ind_to_col_id = dict(zip(range(len(train['PRODUCT'].unique())), train['PRODUCT'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "\n",
    "train_ratings = train['RATING']\n",
    "train_rows = train['USER ID']\n",
    "train_cols = train['PRODUCT']\n",
    "test_ratings = test['RATING']\n",
    "test_rows = test['USER ID']\n",
    "test_cols = test['PRODUCT']\n",
    "\n",
    "m = len(train_ratings) # the size of the training set                             #30352\n",
    "n_rows = user_history['USER ID'].unique().shape[0] # the largest index, plus 1    #4500\n",
    "n_cols = train_cols.unique().shape[0]                                             #75\n",
    "\n",
    "train_rows_inds = np.array([row_id_to_ind[r] for r in train_rows])\n",
    "train_cols_inds = np.array([col_id_to_ind[c] for c in train_cols])\n",
    "\n",
    "test_rows_inds = np.array([row_id_to_ind[r] for r in test_rows])\n",
    "test_cols_inds = np.array([col_id_to_ind[c] for c in test_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_stats = csv.reader(open('train_rating_stats.csv','r'))\n",
    "train_mean_and_std = [row[0] for row in train_data_stats][1:]\n",
    "train_data_mean = float(train_mean_and_std[0])\n",
    "train_data_std = float(train_mean_and_std[1])\n",
    "\n",
    "train_ratings_unnormalized = train_ratings.copy()\n",
    "train_ratings_unnormalized *= train_data_std\n",
    "train_ratings_unnormalized += train_data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(n_rows, n_cols, row_features=np.array([]), col_features=np.array([]), k=15):\n",
    "    \n",
    "    \"\"\"Initalize a random model, and normalize it so that it has sensible mean and variance\"\"\"\n",
    "    # (The normalization helps make sure we start out at a reasonable parameter scale, which speeds up training)\n",
    "    if row_features.size != 0:\n",
    "        k = row_features.shape[1]\n",
    "    elif col_features.size != 0:\n",
    "        k = col_features.shape[1]\n",
    "    if row_features.size == 0:\n",
    "        row_features = np.random.normal(size=(n_rows, k))\n",
    "    else:\n",
    "        row_features -= row_features.mean(axis=1)[:,None]\n",
    "        row_features /= row_features.std(axis=1)[:,None]\n",
    "    if col_features.size == 0:\n",
    "        col_features = np.random.normal(size=(n_cols, k))\n",
    "        \n",
    "    raw_predictions = predict((row_features, col_features))\n",
    "    \n",
    "    s = np.sqrt(2*raw_predictions.std()) # We want to start out with roughly unit variance\n",
    "    b = np.sqrt((train_data_mean - raw_predictions.mean()/s)/k) #We want to start out with average rating 3.5\n",
    "    row_features /= s\n",
    "    row_features += b\n",
    "    col_features /= s\n",
    "    col_features += b\n",
    "    \n",
    "    return (row_features, col_features)\n",
    "\n",
    "def predict(model):\n",
    "    \"\"\"The model's predictions for all row/col pairs\"\"\"\n",
    "    row_features, col_features = model\n",
    "    return row_features @ col_features.T\n",
    "\n",
    "def single_example_step(model, row, col, rating):\n",
    "    \"\"\"Update the model using the gradient at a single training example\"\"\"\n",
    "    row_features, col_features = model\n",
    "    residual = np.dot(row_features[row], col_features[col]) - rating\n",
    "    grad_rows = 2 * residual * col_features[col] # the gradient for the row_features matrix\n",
    "    grad_cols = 2 * residual * row_features[row] # the gradient for the col_features matrix\n",
    "    row_features[row] -= learning_rate*grad_rows\n",
    "    col_features[col] -= learning_rate*grad_cols\n",
    "\n",
    "def train_sgd(model, num_epochs, batch_size):\n",
    "    \"\"\"Train the model for a number of epochs via SGD (batch size=1)\"\"\"\n",
    "    row_features, col_features = model\n",
    "    train_MSEs = []\n",
    "    test_MSEs = []\n",
    "    # It's good practice to shuffle your data before doing batch gradient descent,\n",
    "    # so that each mini-batch peforms like a random sample from the dataset\n",
    "    for epoch in range(num_epochs):\n",
    "        shuffle = np.random.permutation(m) \n",
    "        shuffled_rows = train_rows[shuffle]\n",
    "        shuffled_cols = train_cols[shuffle]\n",
    "        shuffled_ratings = train_ratings[shuffle]\n",
    "        for row, col, rating in zip(shuffled_rows[:batch_size], shuffled_cols[:batch_size], shuffled_ratings[:batch_size]):\n",
    "            # update the model using the gradient at a single example\n",
    "            single_example_step(model, row_id_to_ind[row], col_id_to_ind[col], rating)\n",
    "        # after each Epoch, we'll evaluate our model\n",
    "        predicted = predict(model)        \n",
    "        predicted_unnormalized = predicted.copy()\n",
    "        predicted_unnormalized *= train_data_std\n",
    "        predicted_unnormalized += train_data_mean\n",
    "        train_loss = np.mean((train_ratings_unnormalized - predicted_unnormalized[train_rows_inds, train_cols_inds])**2)\n",
    "        test_loss = np.mean((test_ratings - predicted_unnormalized[test_rows_inds, test_cols_inds])**2)\n",
    "#         print(\"Loss after epoch #{} is: train/{} --- test/{}\".format(epoch+1, train_loss, test_loss))\n",
    "        train_MSEs.append(train_loss)\n",
    "        test_MSEs.append(test_loss)\n",
    "    return predicted_unnormalized, train_MSEs[20:], test_MSEs[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c49568b070>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "row_features = user_history_indexed.to_numpy()\n",
    "sgd_model = initialize(n_rows, n_cols, row_features=row_features)\n",
    "predictions, train_MSEs, test_MSEs = train_sgd(sgd_model, num_epochs=2000, batch_size=100)\n",
    "\n",
    "plt.scatter(np.array(range(len(train_MSEs))), np.array(train_MSEs), s=2, c='b', marker='o')\n",
    "plt.scatter(np.array(range(len(test_MSEs))), np.array(test_MSEs), s=2, c='r', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0265556057606662"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(test_MSEs[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
