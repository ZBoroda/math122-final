{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 4., 4., ..., 5., 5., 3.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "\n",
    "def load_rating_data(file):\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    users = []\n",
    "    movies = []\n",
    "    ratings = []\n",
    "    for row in csv_reader:\n",
    "        # We subtract 1 from the ids to get (0-based) indices\n",
    "        users.append(int(row[\"userId\"])-1)\n",
    "        movies.append(int(row[\"movieId\"])-1)\n",
    "        ratings.append(float(row[\"rating\"]))\n",
    "    users = np.array(users)\n",
    "    movies = np.array(movies)\n",
    "    ratings = np.array(ratings)\n",
    "    return users, movies, ratings\n",
    "\n",
    "with open(\"ratings-train.csv\") as train_file:\n",
    "    train_users, train_movies, train_ratings = load_rating_data(train_file)\n",
    "with open(\"ratings-test.csv\") as test_file:\n",
    "    test_users, test_movies, test_ratings = load_rating_data(test_file)\n",
    "    \n",
    "train_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch #1 is: train/0.9309470853710554 --- test/1.0152979183971957\n",
      "Loss after epoch #2 is: train/0.810306179543858 --- test/0.9261089929226151\n",
      "Loss after epoch #3 is: train/0.7537901733160836 --- test/0.890295285531908\n",
      "Loss after epoch #4 is: train/0.7184458564419317 --- test/0.8718827479159976\n",
      "Loss after epoch #5 is: train/0.6929537191787872 --- test/0.8615704867638968\n",
      "Loss after epoch #6 is: train/0.6728511267669026 --- test/0.855765687070861\n",
      "Loss after epoch #7 is: train/0.655977862546536 --- test/0.8527788995695277\n",
      "Loss after epoch #8 is: train/0.6411523007014377 --- test/0.8517123702420355\n",
      "Loss after epoch #9 is: train/0.6276769862736207 --- test/0.8520442025910373\n",
      "Loss after epoch #10 is: train/0.6151216164774579 --- test/0.8534468901020557\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.005\n",
    "k = 10 # the number of features (for each user/movie)\n",
    "m = len(train_ratings) # the size of the training set\n",
    "n_users = max(train_users)+1 # the largest index, plus 1\n",
    "n_movies = max(train_movies)+1\n",
    "\n",
    "def initialize(n_users, n_movies, k):\n",
    "    \"\"\"Initalize a random model, and normalize it so that it has sensible mean and variance\"\"\"\n",
    "    # (The normalization helps make sure we start out at a reasonable parameter scale, which speeds up training)\n",
    "    user_features = np.random.normal(size=(n_users, k))\n",
    "    movie_features = np.random.normal(size=(n_movies, k))\n",
    "    raw_predictions = predict((user_features, movie_features))\n",
    "    \n",
    "    s = np.sqrt(2*raw_predictions.std()) # We want to start out with roughly unit variance\n",
    "    b = np.sqrt((3.5 - raw_predictions.mean()/s)/k) #We want to start out with average rating 3.5\n",
    "    user_features /= s\n",
    "    user_features += b\n",
    "    movie_features /= s\n",
    "    movie_features += b\n",
    "    \n",
    "    return (user_features, movie_features)\n",
    "\n",
    "def predict(model):\n",
    "    \"\"\"The model's predictions for all user/movie pairs\"\"\"\n",
    "    user_features, movie_features = model\n",
    "    return user_features @ movie_features.T\n",
    "\n",
    "def single_example_step(model, user, movie, rating):\n",
    "    \"\"\"Update the model using the gradient at a single training example\"\"\"\n",
    "    user_features, movie_features = model\n",
    "    residual = np.dot(user_features[user], movie_features[movie]) - rating\n",
    "    grad_users = 2 * residual * movie_features[movie] # the gradient for the user_features matrix\n",
    "    grad_movies = 2 * residual * user_features[user] # the gradient for the movie_features matrix\n",
    "    user_features[user] -= learning_rate*grad_users\n",
    "    movie_features[movie] -= learning_rate*grad_movies\n",
    "\n",
    "def train_sgd(model, epochs):\n",
    "    \"\"\"Train the model for a number of epochs via SGD (batch size=1)\"\"\"\n",
    "    user_features, movie_features = model\n",
    "    # It's good practice to shuffle your data before doing batch gradient descent,\n",
    "    # so that each mini-batch peforms like a random sample from the dataset\n",
    "    shuffle = np.random.permutation(m) \n",
    "    shuffled_users = train_users[shuffle]\n",
    "    shuffled_movies = train_movies[shuffle]\n",
    "    shuffled_ratings = train_ratings[shuffle]\n",
    "    for epoch in range(epochs):\n",
    "        for user, movie, rating in zip(shuffled_users, shuffled_movies, shuffled_ratings):\n",
    "            # update the model using the gradient at a single example\n",
    "            single_example_step(model, user, movie, rating)\n",
    "        # after each Epoch, we'll evaluate our model\n",
    "        predicted = predict(model)\n",
    "        train_loss = np.mean((train_ratings - predicted[train_users, train_movies])**2)\n",
    "        test_loss = np.mean((test_ratings - predicted[test_users, test_movies])**2)\n",
    "        print(\"Loss after epoch #{} is: train/{} --- test/{}\".format(epoch+1, train_loss, test_loss))\n",
    "\n",
    "sgd_model = initialize(n_users, n_movies, k)\n",
    "train_sgd(sgd_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch #1 is: train/2.020499705837473 --- test/2.041398116822025\n",
      "Loss after epoch #2 is: train/1.8452362869045502 --- test/1.865790746658124\n",
      "Loss after epoch #3 is: train/1.7346698915775396 --- test/1.7596933304825082\n",
      "Loss after epoch #4 is: train/1.6533089115962853 --- test/1.6795294299675327\n",
      "Loss after epoch #5 is: train/1.588659848357695 --- test/1.6176778006070938\n",
      "Loss after epoch #6 is: train/1.5349666322235342 --- test/1.565850032869927\n",
      "Loss after epoch #7 is: train/1.4890800486591818 --- test/1.522309095276012\n",
      "Loss after epoch #8 is: train/1.4490750668045365 --- test/1.484344056758278\n",
      "Loss after epoch #9 is: train/1.413681801009058 --- test/1.4510888285122052\n",
      "Loss after epoch #10 is: train/1.3820134039759004 --- test/1.4214149450622864\n",
      "Loss after epoch #11 is: train/1.353422476735558 --- test/1.3947930631991257\n",
      "Loss after epoch #12 is: train/1.3274193638069962 --- test/1.3706614024606327\n",
      "Loss after epoch #13 is: train/1.303623058336582 --- test/1.3486759435000297\n",
      "Loss after epoch #14 is: train/1.2817302186025605 --- test/1.3285140157905175\n",
      "Loss after epoch #15 is: train/1.2614948201997802 --- test/1.309943423503531\n",
      "Loss after epoch #16 is: train/1.2427142797130863 --- test/1.2927585841557545\n",
      "Loss after epoch #17 is: train/1.2252196861540041 --- test/1.2767975889335827\n",
      "Loss after epoch #18 is: train/1.208868719759589 --- test/1.2619199552805942\n",
      "Loss after epoch #19 is: train/1.193540390762186 --- test/1.2480094301821638\n",
      "Loss after epoch #20 is: train/1.1791310439049332 --- test/1.2349653783896333\n",
      "Loss after epoch #21 is: train/1.1655512681354154 --- test/1.2227021255151593\n",
      "Loss after epoch #22 is: train/1.1527234681618257 --- test/1.211145125831714\n",
      "Loss after epoch #23 is: train/1.1405799305020177 --- test/1.2002297709943726\n",
      "Loss after epoch #24 is: train/1.1290612655074945 --- test/1.189899411677465\n",
      "Loss after epoch #25 is: train/1.1181151398963225 --- test/1.1801043251597079\n",
      "Loss after epoch #26 is: train/1.1076952367699515 --- test/1.1708005571216082\n",
      "Loss after epoch #27 is: train/1.0977603959012405 --- test/1.1619491440812855\n",
      "Loss after epoch #28 is: train/1.0882738983258875 --- test/1.1535153722469993\n",
      "Loss after epoch #29 is: train/1.0792028674839218 --- test/1.1454682138335455\n",
      "Loss after epoch #30 is: train/1.0705177652256492 --- test/1.1377798247223592\n",
      "Loss after epoch #31 is: train/1.062191965566093 --- test/1.1304251378950034\n",
      "Loss after epoch #32 is: train/1.054201392550395 --- test/1.1233815100233415\n",
      "Loss after epoch #33 is: train/1.046524211277916 --- test/1.1166284260517196\n",
      "Loss after epoch #34 is: train/1.0391405632251127 --- test/1.1101472440313558\n",
      "Loss after epoch #35 is: train/1.0320323386546009 --- test/1.1039209778719221\n",
      "Loss after epoch #36 is: train/1.0251829802048897 --- test/1.097934109415472\n",
      "Loss after epoch #37 is: train/1.0185773128005144 --- test/1.0921724265184367\n",
      "Loss after epoch #38 is: train/1.0122013958635103 --- test/1.086622882342758\n",
      "Loss after epoch #39 is: train/1.0060423944883594 --- test/1.0812734730425895\n",
      "Loss after epoch #40 is: train/1.0000884667970362 --- test/1.0761131308691918\n",
      "Loss after epoch #41 is: train/0.9943286651444143 --- test/1.071131630569957\n",
      "Loss after epoch #42 is: train/0.9887528492170324 --- test/1.0663195071054554\n",
      "Loss after epoch #43 is: train/0.9833516093758272 --- test/1.061667983136045\n",
      "Loss after epoch #44 is: train/0.9781161988481772 --- test/1.0571689049114352\n",
      "Loss after epoch #45 is: train/0.9730384735864167 --- test/1.0528146854421363\n",
      "Loss after epoch #46 is: train/0.9681108387866147 --- test/1.0485982539826166\n",
      "Loss after epoch #47 is: train/0.9633262012092497 --- test/1.044513011011255\n",
      "Loss after epoch #48 is: train/0.9586779265674723 --- test/1.0405527880054957\n",
      "Loss after epoch #49 is: train/0.9541598013531024 --- test/1.0367118114148757\n",
      "Loss after epoch #50 is: train/0.9497659985586584 --- test/1.0329846703171504\n",
      "Loss after epoch #51 is: train/0.945491046828363 --- test/1.029366287315304\n",
      "Loss after epoch #52 is: train/0.9413298026343809 --- test/1.0258518922930187\n",
      "Loss after epoch #53 is: train/0.9372774251284521 --- test/1.0224369986978459\n",
      "Loss after epoch #54 is: train/0.9333293533650266 --- test/1.0191173820647772\n",
      "Loss after epoch #55 is: train/0.9294812856313194 --- test/1.0158890605302866\n",
      "Loss after epoch #56 is: train/0.9257291606533686 --- test/1.012748277118758\n",
      "Loss after epoch #57 is: train/0.9220691404761273 --- test/1.009691483610584\n",
      "Loss after epoch #58 is: train/0.9184975948405126 --- test/1.0067153258247532\n",
      "Loss after epoch #59 is: train/0.9150110869018432 --- test/1.0038166301690352\n",
      "Loss after epoch #60 is: train/0.9116063601526774 --- test/1.0009923913284011\n",
      "Loss after epoch #61 is: train/0.908280326429177 --- test/0.9982397609775199\n",
      "Loss after epoch #62 is: train/0.9050300548941204 --- test/0.9955560374163585\n",
      "Loss after epoch #63 is: train/0.9018527619018529 --- test/0.9929386560393908\n",
      "Loss after epoch #64 is: train/0.8987458016611026 --- test/0.9903851805589464\n",
      "Loss after epoch #65 is: train/0.8957066576208578 --- test/0.9878932949119679\n",
      "Loss after epoch #66 is: train/0.892732934512643 --- test/0.9854607957871226\n",
      "Loss after epoch #67 is: train/0.8898223509896506 --- test/0.9830855857159446\n",
      "Loss after epoch #68 is: train/0.8869727328094731 --- test/0.980765666677591\n",
      "Loss after epoch #69 is: train/0.8841820065126866 --- test/0.978499134172026\n",
      "Loss after epoch #70 is: train/0.8814481935544277 --- test/0.976284171721038\n",
      "Loss after epoch #71 is: train/0.8787694048504013 --- test/0.9741190457605804\n",
      "Loss after epoch #72 is: train/0.8761438357025887 --- test/0.9720021008915253\n",
      "Loss after epoch #73 is: train/0.8735697610733031 --- test/0.9699317554591366\n",
      "Loss after epoch #74 is: train/0.8710455311792566 --- test/0.967906497434408\n",
      "Loss after epoch #75 is: train/0.8685695673799855 --- test/0.9659248805729618\n",
      "Loss after epoch #76 is: train/0.8661403583373697 --- test/0.9639855208294612\n",
      "Loss after epoch #77 is: train/0.8637564564251253 --- test/0.962087093007528\n",
      "Loss after epoch #78 is: train/0.8614164743690595 --- test/0.9602283276269569\n",
      "Loss after epoch #79 is: train/0.859119082100593 --- test/0.9584080079916574\n",
      "Loss after epoch #80 is: train/0.8568630038075995 --- test/0.9566249674432116\n",
      "Loss after epoch #81 is: train/0.8546470151679887 --- test/0.9548780867862486\n",
      "Loss after epoch #82 is: train/0.8524699407527219 --- test/0.9531662918730244\n",
      "Loss after epoch #83 is: train/0.8503306515860554 --- test/0.9514885513356653\n",
      "Loss after epoch #84 is: train/0.8482280628518438 --- test/0.9498438744554962\n",
      "Loss after epoch #85 is: train/0.8461611317356394 --- test/0.9482313091597465\n",
      "Loss after epoch #86 is: train/0.8441288553931666 --- test/0.9466499401367315\n",
      "Loss after epoch #87 is: train/0.842130269036504 --- test/0.9450988870613015\n",
      "Loss after epoch #88 is: train/0.8401644441299913 --- test/0.9435773029230288\n",
      "Loss after epoch #89 is: train/0.8382304866885038 --- test/0.9420843724501772\n",
      "Loss after epoch #90 is: train/0.8363275356713101 --- test/0.9406193106230485\n",
      "Loss after epoch #91 is: train/0.8344547614652406 --- test/0.9391813612707887\n",
      "Loss after epoch #92 is: train/0.83261136445137 --- test/0.9377697957461897\n",
      "Loss after epoch #93 is: train/0.8307965736498562 --- test/0.9363839116734289\n",
      "Loss after epoch #94 is: train/0.829009645437961 --- test/0.9350230317640688\n",
      "Loss after epoch #95 is: train/0.8272498623366549 --- test/0.9336865026969772\n",
      "Loss after epoch #96 is: train/0.8255165318615276 --- test/0.9323736940581533\n",
      "Loss after epoch #97 is: train/0.823808985434042 --- test/0.9310839973367249\n",
      "Loss after epoch #98 is: train/0.8221265773494429 --- test/0.929816824973649\n",
      "Loss after epoch #99 is: train/0.8204686837978926 --- test/0.9285716094599047\n",
      "Loss after epoch #100 is: train/0.8188347019356419 --- test/0.9273478024811702\n"
     ]
    }
   ],
   "source": [
    " def all_examples_step(model):\n",
    "    \"\"\"Update the model using the gradient averaged over all training examples\"\"\"\n",
    "    user_features, movie_features = model\n",
    "    # To average the gradient over all training examples, it's convenient to\n",
    "    #    initialize arrays of zeros to hold the full gradients, and then update\n",
    "    #    these arrays at each training example, just like in the SGD procedure\n",
    "    grad_users = np.zeros_like(user_features)\n",
    "    grad_movies = np.zeros_like(movie_features)\n",
    "    # We only need to compute the model's predicted ratings once\n",
    "    predicted = predict(model)\n",
    "    for user, movie, rating in zip(train_users, train_movies, train_ratings):\n",
    "        # Mimic the SGD procedure, but store the gradients so they can be averaged\n",
    "        residual = predicted[user, movie] - rating\n",
    "        grad_users[user] += 2 * residual * movie_features[movie]\n",
    "        grad_movies[movie] += 2 * residual * user_features[user]\n",
    "    user_features -= learning_rate/m * grad_users # Update using the averaged gradients\n",
    "    movie_features -= learning_rate/m * grad_movies\n",
    "\n",
    "    \n",
    "def train_full(model, epochs):\n",
    "    \"\"\"Train the model for a number of epochs using gradients estimated from the entire training set\"\"\"\n",
    "    user_features, movie_features = model\n",
    "    for epoch in range(epochs):\n",
    "        all_examples_step(model)\n",
    "        predicted = predict(model)\n",
    "        train_loss = np.mean((train_ratings - predicted[train_users, train_movies])**2)\n",
    "        test_loss = np.mean((test_ratings - predicted[test_users, test_movies])**2)\n",
    "        print(\"Loss after epoch #{} is: train/{} --- test/{}\".format(epoch+1, train_loss, test_loss))\n",
    "        \n",
    "full_model = initialize(n_users, n_movies, k)\n",
    "learning_rate = 8. # Since we are averaging very sparse gradients,\n",
    "# the gradients will be small and we can use a large learning rate\n",
    "train_full(full_model, 100) # We only get a single update to the model from each epoch, so we'll need a lot more epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch #1 is: train/0.9796749884518493 --- test/1.0411660488539876\n",
      "Loss after epoch #2 is: train/0.8437374393115624 --- test/0.925966987361918\n",
      "Loss after epoch #3 is: train/0.784311191958209 --- test/0.8829530230630737\n",
      "Loss after epoch #4 is: train/0.7489426708883228 --- test/0.8611252495609698\n",
      "Loss after epoch #5 is: train/0.7245977046432523 --- test/0.8483312823137272\n",
      "Loss after epoch #6 is: train/0.7063208459315726 --- test/0.8402340279084958\n",
      "Loss after epoch #7 is: train/0.6917601707419518 --- test/0.8349122722847582\n",
      "Loss after epoch #8 is: train/0.6796369806969069 --- test/0.8313865436232689\n",
      "Loss after epoch #9 is: train/0.6691896456852302 --- test/0.8291039647521733\n",
      "Loss after epoch #10 is: train/0.6599343294677924 --- test/0.8277265922024674\n"
     ]
    }
   ],
   "source": [
    "# k=5\n",
    "learning_rate = 0.005\n",
    "k = 5 # the number of features (for each user/movie)\n",
    "m = len(train_ratings) # the size of the training set\n",
    "n_users = max(train_users)+1 # the largest index, plus 1\n",
    "n_movies = max(train_movies)+1\n",
    "\n",
    "\n",
    "sgd_model = initialize(n_users, n_movies, k)\n",
    "train_sgd(sgd_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch #1 is: train/0.9107490224332668 --- test/1.0244002481638164\n",
      "Loss after epoch #2 is: train/0.7903246204202476 --- test/0.9343603225841822\n",
      "Loss after epoch #3 is: train/0.7314271132558519 --- test/0.8973574367684758\n",
      "Loss after epoch #4 is: train/0.6933162072776323 --- test/0.8787343859615363\n",
      "Loss after epoch #5 is: train/0.6648578208137972 --- test/0.8689558249653597\n",
      "Loss after epoch #6 is: train/0.6415847904793435 --- test/0.8642175541220632\n",
      "Loss after epoch #7 is: train/0.6213306212223534 --- test/0.8626972005379843\n",
      "Loss after epoch #8 is: train/0.602929240882611 --- test/0.8634097649480269\n",
      "Loss after epoch #9 is: train/0.5857218599711521 --- test/0.8657695011093927\n",
      "Loss after epoch #10 is: train/0.5693365174623799 --- test/0.8693973044897281\n"
     ]
    }
   ],
   "source": [
    "# k=15\n",
    "learning_rate = 0.005\n",
    "k = 15 # the number of features (for each user/movie)\n",
    "m = len(train_ratings) # the size of the training set\n",
    "n_users = max(train_users)+1 # the largest index, plus 1\n",
    "n_movies = max(train_movies)+1\n",
    "\n",
    "sgd_model = initialize(n_users, n_movies, k)\n",
    "train_sgd(sgd_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch #1 is: train/0.8826911106673225 --- test/0.9798710565376084\n",
      "Loss after epoch #2 is: train/0.7576263129044959 --- test/0.9152627330836701\n",
      "Loss after epoch #3 is: train/0.6904738091783367 --- test/0.8908730561148943\n",
      "Loss after epoch #4 is: train/0.6435845922399914 --- test/0.8806929549738497\n",
      "Loss after epoch #5 is: train/0.6060401289782779 --- test/0.8775516029910546\n",
      "Loss after epoch #6 is: train/0.5734216363750773 --- test/0.8786278871027476\n",
      "Loss after epoch #7 is: train/0.5436757440573078 --- test/0.8825768676231919\n",
      "Loss after epoch #8 is: train/0.5158304999765658 --- test/0.888649651986109\n",
      "Loss after epoch #9 is: train/0.48947223113411986 --- test/0.8963541432566015\n",
      "Loss after epoch #10 is: train/0.4644765471384368 --- test/0.9053089464739565\n"
     ]
    }
   ],
   "source": [
    "# k=15\n",
    "learning_rate = 0.005\n",
    "k = 30 # the number of features (for each user/movie)\n",
    "m = len(train_ratings) # the size of the training set\n",
    "n_users = max(train_users)+1 # the largest index, plus 1\n",
    "n_movies = max(train_movies)+1\n",
    "\n",
    "sgd_model = initialize(n_users, n_movies, k)\n",
    "train_sgd(sgd_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch #1 is: train/0.9324304990798615 --- test/1.0401212085123999\n",
      "Loss after epoch #2 is: train/0.8081840125315494 --- test/0.9383605117721585\n",
      "Loss after epoch #3 is: train/0.7509945633018889 --- test/0.8979239486277207\n",
      "Loss after epoch #4 is: train/0.7155744790345461 --- test/0.8769689255431026\n",
      "Loss after epoch #5 is: train/0.690160819674249 --- test/0.8649548392672366\n",
      "Loss after epoch #6 is: train/0.670201422555586 --- test/0.8578976502169289\n",
      "Loss after epoch #7 is: train/0.653518526085807 --- test/0.8539350537810769\n",
      "Loss after epoch #8 is: train/0.6389266811313314 --- test/0.8520744518431724\n",
      "Loss after epoch #9 is: train/0.6257257595461857 --- test/0.8517360299984773\n",
      "Loss after epoch #10 is: train/0.6134813502160514 --- test/0.8525555183149279\n"
     ]
    }
   ],
   "source": [
    "# k=10\n",
    "learning_rate = 0.005\n",
    "k = 10 # the number of features (for each user/movie)\n",
    "m = len(train_ratings) # the size of the training set\n",
    "n_users = max(train_users)+1 # the largest index, plus 1\n",
    "n_movies = max(train_movies)+1\n",
    "\n",
    "sgd_model = initialize(n_users, n_movies, k)\n",
    "train_sgd(sgd_model, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
